{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.MLP import MLP\n",
    "# from src.validate import validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the provided dataset\n",
    "file_path = 'data/data_100000.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jihoon\\miniconda3\\envs\\torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Training Progress:   1%|          | 1/100 [00:03<05:12,  3.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Avg Loss: 0.4137, Train R2: 0.9797, Train RMSE: 0.2972, Test R2: 0.9785, Test RMSE: 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [00:06<05:11,  3.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Avg Loss: 0.0798, Train R2: 0.9868, Train RMSE: 0.2312, Test R2: 0.9857, Test RMSE: 0.2411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [00:09<05:10,  3.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Avg Loss: 0.0559, Train R2: 0.9900, Train RMSE: 0.2049, Test R2: 0.9891, Test RMSE: 0.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 4/100 [00:12<05:08,  3.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Avg Loss: 0.0456, Train R2: 0.9922, Train RMSE: 0.1793, Test R2: 0.9913, Test RMSE: 0.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▌         | 5/100 [00:16<05:05,  3.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Avg Loss: 0.0401, Train R2: 0.9921, Train RMSE: 0.1853, Test R2: 0.9913, Test RMSE: 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 6/100 [00:19<04:59,  3.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Avg Loss: 0.0355, Train R2: 0.9936, Train RMSE: 0.1555, Test R2: 0.9931, Test RMSE: 0.1618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 7/100 [00:22<04:54,  3.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Avg Loss: 0.0334, Train R2: 0.9936, Train RMSE: 0.1652, Test R2: 0.9933, Test RMSE: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 8/100 [00:26<05:08,  3.35s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Avg Loss: 0.0296, Train R2: 0.9932, Train RMSE: 0.1733, Test R2: 0.9927, Test RMSE: 0.1767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [00:30<05:28,  3.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Avg Loss: 0.0285, Train R2: 0.9912, Train RMSE: 0.1947, Test R2: 0.9902, Test RMSE: 0.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 10/100 [00:33<05:28,  3.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Avg Loss: 0.0272, Train R2: 0.9939, Train RMSE: 0.1536, Test R2: 0.9934, Test RMSE: 0.1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  11%|█         | 11/100 [00:37<05:23,  3.64s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Avg Loss: 0.0246, Train R2: 0.9929, Train RMSE: 0.1786, Test R2: 0.9924, Test RMSE: 0.1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|█▏        | 12/100 [00:41<05:20,  3.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Avg Loss: 0.0238, Train R2: 0.9951, Train RMSE: 0.1405, Test R2: 0.9947, Test RMSE: 0.1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  13%|█▎        | 13/100 [00:45<05:26,  3.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Avg Loss: 0.0225, Train R2: 0.9948, Train RMSE: 0.1446, Test R2: 0.9943, Test RMSE: 0.1517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|█▍        | 14/100 [00:49<05:30,  3.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Avg Loss: 0.0227, Train R2: 0.9948, Train RMSE: 0.1479, Test R2: 0.9944, Test RMSE: 0.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  15%|█▌        | 15/100 [00:52<05:23,  3.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Avg Loss: 0.0206, Train R2: 0.9953, Train RMSE: 0.1427, Test R2: 0.9951, Test RMSE: 0.1435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 16/100 [00:56<05:12,  3.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Avg Loss: 0.0206, Train R2: 0.9958, Train RMSE: 0.1243, Test R2: 0.9955, Test RMSE: 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  17%|█▋        | 17/100 [01:00<05:05,  3.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Avg Loss: 0.0203, Train R2: 0.9954, Train RMSE: 0.1359, Test R2: 0.9951, Test RMSE: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|█▊        | 18/100 [01:03<05:00,  3.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Avg Loss: 0.0191, Train R2: 0.9958, Train RMSE: 0.1284, Test R2: 0.9954, Test RMSE: 0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  19%|█▉        | 19/100 [01:07<05:00,  3.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Avg Loss: 0.0190, Train R2: 0.9944, Train RMSE: 0.1564, Test R2: 0.9940, Test RMSE: 0.1614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 20/100 [01:11<04:57,  3.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Avg Loss: 0.0176, Train R2: 0.9962, Train RMSE: 0.1213, Test R2: 0.9958, Test RMSE: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  21%|██        | 21/100 [01:15<04:56,  3.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Avg Loss: 0.0177, Train R2: 0.9966, Train RMSE: 0.1121, Test R2: 0.9963, Test RMSE: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  22%|██▏       | 22/100 [01:19<04:56,  3.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Avg Loss: 0.0171, Train R2: 0.9958, Train RMSE: 0.1250, Test R2: 0.9957, Test RMSE: 0.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  23%|██▎       | 23/100 [01:22<04:49,  3.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Avg Loss: 0.0169, Train R2: 0.9959, Train RMSE: 0.1252, Test R2: 0.9956, Test RMSE: 0.1296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  24%|██▍       | 24/100 [01:27<05:00,  3.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Avg Loss: 0.0183, Train R2: 0.9966, Train RMSE: 0.1137, Test R2: 0.9962, Test RMSE: 0.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  25%|██▌       | 25/100 [01:30<04:50,  3.87s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Avg Loss: 0.0161, Train R2: 0.9952, Train RMSE: 0.1288, Test R2: 0.9950, Test RMSE: 0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  26%|██▌       | 26/100 [01:34<04:39,  3.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Avg Loss: 0.0167, Train R2: 0.9968, Train RMSE: 0.1112, Test R2: 0.9966, Test RMSE: 0.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  27%|██▋       | 27/100 [01:38<04:33,  3.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Avg Loss: 0.0169, Train R2: 0.9958, Train RMSE: 0.1298, Test R2: 0.9954, Test RMSE: 0.1373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  28%|██▊       | 28/100 [01:41<04:25,  3.69s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Avg Loss: 0.0159, Train R2: 0.9967, Train RMSE: 0.1110, Test R2: 0.9964, Test RMSE: 0.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  29%|██▉       | 29/100 [01:45<04:19,  3.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Avg Loss: 0.0146, Train R2: 0.9968, Train RMSE: 0.1084, Test R2: 0.9966, Test RMSE: 0.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 30/100 [01:48<04:18,  3.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Avg Loss: 0.0143, Train R2: 0.9965, Train RMSE: 0.1148, Test R2: 0.9963, Test RMSE: 0.1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  31%|███       | 31/100 [01:52<04:10,  3.63s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Avg Loss: 0.0146, Train R2: 0.9970, Train RMSE: 0.1068, Test R2: 0.9968, Test RMSE: 0.1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  32%|███▏      | 32/100 [01:56<04:05,  3.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Avg Loss: 0.0158, Train R2: 0.9958, Train RMSE: 0.1353, Test R2: 0.9955, Test RMSE: 0.1386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  33%|███▎      | 33/100 [01:59<04:02,  3.62s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Avg Loss: 0.0146, Train R2: 0.9959, Train RMSE: 0.1361, Test R2: 0.9956, Test RMSE: 0.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  34%|███▍      | 34/100 [02:03<04:01,  3.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Avg Loss: 0.0138, Train R2: 0.9967, Train RMSE: 0.1125, Test R2: 0.9964, Test RMSE: 0.1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  35%|███▌      | 35/100 [02:07<03:57,  3.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Avg Loss: 0.0139, Train R2: 0.9968, Train RMSE: 0.1075, Test R2: 0.9967, Test RMSE: 0.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  35%|███▌      | 35/100 [02:10<04:03,  3.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Avg Loss: 0.0140, Train R2: 0.9967, Train RMSE: 0.1170, Test R2: 0.9963, Test RMSE: 0.1242\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Convert dataset to PyTorch tensors\n",
    "X = torch.tensor(data[['l2', 'l3', 'l4', 'EE_x', 'EE_y']].values, dtype=torch.float32)\n",
    "y = torch.tensor(data[['d_max', 'gr_min']].values, dtype=torch.float32)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = torch.tensor(scaler.fit_transform(X_train), dtype=torch.float32)\n",
    "X_test = torch.tensor(scaler.transform(X_test), dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "model = MLP(in_channels=5, dim=50, out_channels=2)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# Early stopping parameters\n",
    "best_test_rmse = float('inf')\n",
    "patience, patience_counter = 5, 0\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training Progress\", unit=\"epoch\"):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode for testing\n",
    "    with torch.no_grad():\n",
    "        # Predict on training set\n",
    "        train_preds = model(X_train).numpy()\n",
    "        train_r2 = r2_score(y_train.numpy(), train_preds)\n",
    "        train_rmse = rmse(y_train.numpy(), train_preds)\n",
    "\n",
    "        # Predict on testing set\n",
    "        test_preds = model(X_test).numpy()\n",
    "        test_r2 = r2_score(y_test.numpy(), test_preds)\n",
    "        test_rmse = rmse(y_test.numpy(), test_preds)\n",
    "\n",
    "    # Print progress at the end of each epoch\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Avg Loss: {train_loss/len(train_loader):.4f}, '\n",
    "          f'Train R2: {train_r2:.4f}, Train RMSE: {train_rmse:.4f}, '\n",
    "          f'Test R2: {test_r2:.4f}, Test RMSE: {test_rmse:.4f}')\n",
    "\n",
    "    # Early stopping logic\n",
    "    if test_rmse < best_test_rmse:\n",
    "        best_test_rmse = test_rmse\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jihoon\\miniconda3\\envs\\torch\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\Users\\Jihoon\\miniconda3\\envs\\torch\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg    \tstd    \tmin      \tmax    \n",
      "0  \t100   \t3.92119\t3.62648\t0.0233234\t13.9503\n",
      "1  \t179   \t0.991598\t1.08333\t0.00771701\t5.71452\n",
      "2  \t179   \t0.308785\t0.231944\t0.00771701\t1.38438\n",
      "3  \t180   \t0.200795\t0.226375\t0.000628114\t1.06641\n",
      "4  \t179   \t0.20169 \t0.301665\t0.000628114\t2.3862 \n",
      "5  \t188   \t0.131348\t0.213798\t0.000628114\t1.06641\n",
      "6  \t176   \t0.0856175\t0.146118\t0.000202298\t0.799603\n",
      "7  \t179   \t0.0718635\t0.125091\t0.000202298\t0.704628\n",
      "8  \t178   \t0.0645908\t0.114943\t0.000202298\t0.614002\n",
      "9  \t180   \t0.0704572\t0.133923\t0.000202298\t0.614002\n",
      "10 \t180   \t0.0636913\t0.121877\t0.000202298\t0.548784\n",
      "11 \t178   \t0.0641021\t0.108312\t0.000202298\t0.548784\n",
      "12 \t181   \t0.0496651\t0.0972456\t0.000202298\t0.548784\n",
      "13 \t180   \t0.0403555\t0.0763738\t0.000202298\t0.357693\n",
      "14 \t178   \t0.0480341\t0.0921784\t0.000202298\t0.357693\n",
      "15 \t181   \t0.0690589\t0.113851 \t0.000202298\t0.357693\n",
      "16 \t179   \t0.113259 \t0.145791 \t0.000202298\t0.357693\n",
      "17 \t182   \t0.147064 \t0.15784  \t0.000202298\t0.318011\n",
      "18 \t179   \t0.140873 \t0.157081 \t0.000202298\t0.318011\n",
      "19 \t177   \t0.141112 \t0.156919 \t0.000202298\t0.318011\n",
      "20 \t180   \t0.137989 \t0.156473 \t0.000202298\t0.318011\n",
      "21 \t181   \t0.143917 \t0.157535 \t0.000202298\t0.318011\n",
      "22 \t182   \t0.139299 \t0.156875 \t0.000202298\t0.318011\n",
      "23 \t181   \t0.130117 \t0.155094 \t0.000202298\t0.318011\n",
      "24 \t183   \t0.134874 \t0.155958 \t0.000202298\t0.318011\n",
      "25 \t183   \t0.13024  \t0.155035 \t0.000202298\t0.318011\n",
      "26 \t181   \t0.128723 \t0.154674 \t0.000202298\t0.318011\n",
      "27 \t178   \t0.128658 \t0.154724 \t0.000202298\t0.318011\n",
      "28 \t180   \t0.13457  \t0.156159 \t0.000202298\t0.318011\n",
      "29 \t172   \t0.131524 \t0.15552  \t0.000202298\t0.318011\n",
      "30 \t172   \t0.129933 \t0.15523  \t0.000202298\t0.318011\n",
      "31 \t177   \t0.134825 \t0.155988 \t0.000202298\t0.318011\n",
      "32 \t181   \t0.134628 \t0.156113 \t0.000202298\t0.318011\n",
      "33 \t183   \t0.127107 \t0.154361 \t0.000202298\t0.318011\n",
      "34 \t178   \t0.120869 \t0.152814 \t0.000202298\t0.318011\n",
      "35 \t177   \t0.11155  \t0.149952 \t0.000202298\t0.318011\n",
      "36 \t182   \t0.11176  \t0.149844 \t0.000202298\t0.318011\n",
      "37 \t184   \t0.128474 \t0.154822 \t0.000202298\t0.318011\n",
      "38 \t180   \t0.131737 \t0.155386 \t0.000202298\t0.318011\n",
      "39 \t179   \t0.130187 \t0.155066 \t0.000202298\t0.318011\n",
      "40 \t177   \t0.122492 \t0.15318  \t0.000202298\t0.318011\n",
      "41 \t174   \t0.125477 \t0.154053 \t0.000202298\t0.318011\n",
      "42 \t174   \t0.130173 \t0.155077 \t0.000202298\t0.318011\n",
      "43 \t179   \t0.131491 \t0.155547 \t0.000202298\t0.318011\n",
      "44 \t182   \t0.131489 \t0.155548 \t0.000202298\t0.318011\n",
      "45 \t178   \t0.12998  \t0.155194 \t0.000202298\t0.318011\n",
      "46 \t177   \t0.120957 \t0.152752 \t0.000202298\t0.318011\n",
      "47 \t176   \t0.117609 \t0.152006 \t0.000202298\t0.318011\n",
      "48 \t185   \t0.126769 \t0.154585 \t0.000202298\t0.318011\n",
      "49 \t185   \t0.126788 \t0.154572 \t0.000202298\t0.318011\n",
      "50 \t173   \t0.127061 \t0.154398 \t8.4877e-05 \t0.318011\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "TARGET_D_MAX = 1.0 \n",
    "TARGET_GR_MIN = 2.0\n",
    "\n",
    "BOUNDS = [(0.050001, 0.9497), (0.083289, 2.0), (0.093218, 2.907), (-0.49998, 2.5), (-1.5, 1.5)]\n",
    "# BOUNDS = [(-5, 5), (-5, 5), (-5, 5), (-5, 5), (-5, 5)]\n",
    "\n",
    "# Surrogate model prediction function\n",
    "def surrogate_model_predict(individual):\n",
    "    input_tensor = torch.tensor([individual], dtype=torch.float32)\n",
    "    scaled_input = torch.tensor(scaler.transform(input_tensor), dtype=torch.float32)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_targets = model(scaled_input)\n",
    "    d_max_pred, gr_min_pred = predicted_targets.numpy()[0]\n",
    "    return d_max_pred, gr_min_pred\n",
    "\n",
    "# Fitness function\n",
    "def evaluate(individual):\n",
    "    # d_max_pred, gr_min_pred = surrogate_model_predict(individual)\n",
    "    d_max_pred, gr_min_pred = surrogate_model_predict(individual)\n",
    "    # TARGET_D_MAX = 0.5  # Replace with your actual target\n",
    "    # TARGET_GR_MIN = 0.5  # Replace with your actual target\n",
    "    return abs(d_max_pred - TARGET_D_MAX), abs(gr_min_pred - TARGET_GR_MIN)\n",
    "\n",
    "# Set up DEAP\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, lambda: [random.uniform(b[0], b[1]) for b in BOUNDS])\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "def checkBounds(min, max):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            offspring = func(*args, **kwargs)\n",
    "            for child in offspring:\n",
    "                for i in range(len(child)):\n",
    "                    if child[i] > max[i]:\n",
    "                        child[i] = max[i]\n",
    "                    elif child[i] < min[i]:\n",
    "                        child[i] = min[i]\n",
    "            return offspring\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "toolbox.decorate(\"mate\", checkBounds([b[0] for b in BOUNDS], [b[1] for b in BOUNDS]))\n",
    "toolbox.decorate(\"mutate\", checkBounds([b[0] for b in BOUNDS], [b[1] for b in BOUNDS]))\n",
    "\n",
    "# NSGA-II Algorithm\n",
    "def main():\n",
    "    NGEN = 50  # Number of generations\n",
    "    MU = 100    # Population size\n",
    "    LAMBDA = 200\n",
    "    CXPB = 0.7\n",
    "    MUTPB = 0.2\n",
    "\n",
    "    pop = toolbox.population(n=MU)\n",
    "    hof = tools.ParetoFront()\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    algorithms.eaMuPlusLambda(pop, toolbox, mu=MU, lambda_=LAMBDA, cxpb=CXPB, mutpb=MUTPB, \n",
    "                             ngen=NGEN, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    return pop, stats, hof\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats, hof = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg    \tstd    \tmin       \tmax    \n",
      "0  \t100   \t5.56649\t4.01312\t0.00480331\t19.7194\n",
      "1  \t178   \t2.09404\t1.85069\t0.00432282\t11.9883\n",
      "2  \t182   \t1.10058\t1.78172\t0.00432282\t11.9883\n",
      "3  \t177   \t0.294625\t0.350914\t0.00221289\t1.53734\n",
      "4  \t178   \t0.141709\t0.195743\t0.000219887\t1.17147\n",
      "5  \t186   \t0.112507\t0.172427\t0.000219887\t1.17147\n",
      "6  \t177   \t0.108457\t0.118065\t0.000219887\t0.577624\n",
      "7  \t180   \t0.110925\t0.122889\t0.000219887\t0.577624\n",
      "8  \t177   \t0.115846\t0.14524 \t0.000219887\t0.583227\n",
      "9  \t183   \t0.0817945\t0.098956\t2.84076e-05\t0.27188 \n",
      "10 \t179   \t0.0619448\t0.0847678\t2.84076e-05\t0.237076\n",
      "11 \t175   \t0.0235054\t0.0456666\t2.84076e-05\t0.237076\n",
      "12 \t184   \t0.02516  \t0.0479361\t2.84076e-05\t0.237076\n",
      "13 \t178   \t0.0188189\t0.0339919\t2.84076e-05\t0.237076\n",
      "14 \t173   \t0.0177922\t0.0304254\t2.84076e-05\t0.237076\n",
      "15 \t183   \t0.0202935\t0.0373963\t2.84076e-05\t0.237076\n",
      "16 \t180   \t0.0216156\t0.0408208\t2.84076e-05\t0.237076\n",
      "17 \t176   \t0.0178578\t0.0301537\t2.84076e-05\t0.237076\n",
      "18 \t183   \t0.0174453\t0.0315192\t2.84076e-05\t0.237076\n",
      "19 \t179   \t0.0169115\t0.0293834\t2.84076e-05\t0.237076\n",
      "20 \t182   \t0.0157733\t0.0248971\t2.84076e-05\t0.237076\n",
      "21 \t181   \t0.0177337\t0.0318625\t2.84076e-05\t0.237076\n",
      "22 \t171   \t0.0168124\t0.0293831\t2.84076e-05\t0.237076\n",
      "23 \t183   \t0.0176404\t0.0318625\t2.84076e-05\t0.237076\n",
      "24 \t177   \t0.0165897\t0.0278153\t2.84076e-05\t0.237076\n",
      "25 \t190   \t0.016683 \t0.0278188\t2.84076e-05\t0.237076\n",
      "26 \t182   \t0.0177337\t0.0318625\t2.84076e-05\t0.237076\n",
      "27 \t181   \t0.016683 \t0.0278188\t2.84076e-05\t0.237076\n",
      "28 \t176   \t0.0174395\t0.0315213\t2.84076e-05\t0.237076\n",
      "29 \t180   \t0.0185617\t0.0341401\t2.84076e-05\t0.237076\n",
      "30 \t177   \t0.0173463\t0.0315205\t2.84076e-05\t0.237076\n",
      "31 \t186   \t0.0176404\t0.0318625\t2.84076e-05\t0.237076\n",
      "32 \t179   \t0.0173463\t0.0315205\t2.84076e-05\t0.237076\n",
      "33 \t180   \t0.0167872\t0.0292543\t2.84076e-05\t0.237076\n",
      "34 \t184   \t0.0162787\t0.0284929\t2.84076e-05\t0.237076\n",
      "35 \t182   \t0.0169749\t0.0309395\t2.84076e-05\t0.237076\n",
      "36 \t182   \t0.0169749\t0.0309395\t2.84076e-05\t0.237076\n",
      "37 \t183   \t0.0160655\t0.0284936\t2.84076e-05\t0.237076\n",
      "38 \t178   \t0.0170815\t0.0309362\t2.84076e-05\t0.237076\n",
      "39 \t174   \t0.0170815\t0.0309362\t2.84076e-05\t0.237076\n",
      "40 \t180   \t0.0177776\t0.0331864\t2.84076e-05\t0.237076\n",
      "41 \t175   \t0.0169749\t0.0309395\t2.84076e-05\t0.237076\n",
      "42 \t178   \t0.0181416\t0.0345991\t2.84076e-05\t0.237076\n",
      "43 \t179   \t0.0160449\t0.0267052\t2.84076e-05\t0.237076\n",
      "44 \t179   \t0.0170956\t0.0309167\t2.84076e-05\t0.237076\n",
      "45 \t184   \t0.0171097\t0.0308971\t2.84076e-05\t0.237076\n",
      "46 \t187   \t0.0179219\t0.0331369\t2.84076e-05\t0.237076\n",
      "47 \t176   \t0.016307 \t0.0284513\t2.84076e-05\t0.237076\n",
      "48 \t182   \t0.0162004\t0.0284519\t2.84076e-05\t0.237076\n",
      "49 \t182   \t0.016989 \t0.03092  \t2.84076e-05\t0.237076\n",
      "50 \t183   \t0.0170031\t0.0309005\t2.84076e-05\t0.237076\n",
      "Results for set 1 saved to ./synthesis_100k/NSGA-II_v2\\nsga_ii_results_set_1_0.4_5.0.csv\n",
      "gen\tnevals\tavg    \tstd    \tmin      \tmax   \n",
      "0  \t100   \t6.01987\t4.10456\t0.0136116\t16.901\n",
      "1  \t179   \t2.86919\t2.33968\t0.0136116\t10.1338\n",
      "2  \t182   \t1.69304\t1.89067\t0.00825441\t11.5558\n",
      "3  \t181   \t1.10903\t2.02225\t0.00334352\t11.5558\n",
      "4  \t170   \t0.516124\t0.823826\t0.000683457\t3.85356\n",
      "5  \t174   \t0.342913\t0.579326\t0.000683457\t2.6525 \n",
      "6  \t177   \t0.259751\t0.466199\t0.000683457\t2.6525 \n",
      "7  \t173   \t0.271449\t0.467727\t3.91006e-05\t2.29029\n",
      "8  \t177   \t0.288638\t0.566282\t3.91006e-05\t3.37679\n",
      "9  \t181   \t0.306546\t0.630268\t3.91006e-05\t3.37679\n",
      "10 \t178   \t0.490016\t0.794298\t3.91006e-05\t3.37679\n",
      "11 \t179   \t0.61823 \t0.961618\t3.91006e-05\t3.37679\n",
      "12 \t183   \t0.678746\t0.963971\t3.91006e-05\t3.37679\n",
      "13 \t175   \t1.06747 \t1.14945 \t3.91006e-05\t3.37679\n",
      "14 \t182   \t1.02296 \t1.1542  \t3.91006e-05\t3.37679\n",
      "15 \t183   \t0.905456\t1.13054 \t3.91006e-05\t3.37679\n",
      "16 \t183   \t0.657001\t1.02506 \t3.91006e-05\t3.37679\n",
      "17 \t186   \t0.247707\t0.594118\t3.91006e-05\t3.37679\n",
      "18 \t180   \t0.239698\t0.526664\t3.91006e-05\t3.37679\n",
      "19 \t185   \t0.0915116\t0.176819\t3.91006e-05\t1.23822\n",
      "20 \t182   \t0.0599288\t0.167753\t3.91006e-05\t1.23822\n",
      "21 \t188   \t0.034971 \t0.13508 \t3.91006e-05\t1.23822\n",
      "22 \t177   \t0.0489603\t0.158973\t3.91006e-05\t1.23822\n",
      "23 \t188   \t0.0465474\t0.137085\t3.91006e-05\t1.23822\n",
      "24 \t177   \t0.0424447\t0.1318  \t3.91006e-05\t1.23822\n",
      "25 \t186   \t0.0432119\t0.131748\t3.91006e-05\t1.23822\n",
      "26 \t175   \t0.0451365\t0.134623\t3.91006e-05\t1.23822\n",
      "27 \t178   \t0.039011 \t0.104754\t3.91006e-05\t1.23822\n",
      "28 \t176   \t0.0390273\t0.104765\t3.91006e-05\t1.23822\n",
      "29 \t182   \t0.0408219\t0.107968\t3.91006e-05\t1.23822\n",
      "30 \t184   \t0.0366208\t0.0977041\t3.91006e-05\t1.18378\n",
      "31 \t177   \t0.0370044\t0.097693 \t3.91006e-05\t1.18378\n",
      "32 \t179   \t0.0370044\t0.097693 \t3.91006e-05\t1.18378\n",
      "33 \t173   \t0.0389127\t0.101642 \t3.91006e-05\t1.18378\n",
      "34 \t175   \t0.0428104\t0.127234 \t3.91006e-05\t1.18378\n",
      "35 \t177   \t0.0483238\t0.150214 \t3.91006e-05\t1.18378\n",
      "36 \t183   \t0.0370044\t0.097693 \t3.91006e-05\t1.18378\n",
      "37 \t185   \t0.0443969\t0.129838 \t3.91006e-05\t1.18378\n",
      "38 \t177   \t0.0443969\t0.129838 \t3.91006e-05\t1.18378\n",
      "39 \t187   \t0.0443969\t0.129838 \t3.91006e-05\t1.18378\n",
      "40 \t182   \t0.0443969\t0.129838 \t3.91006e-05\t1.18378\n",
      "41 \t176   \t0.0445887\t0.129823 \t3.91006e-05\t1.18378\n",
      "42 \t178   \t0.0426641\t0.126831 \t3.91006e-05\t1.18378\n",
      "43 \t180   \t0.0426641\t0.126831 \t3.91006e-05\t1.18378\n",
      "44 \t182   \t0.0368126\t0.0976987\t3.91006e-05\t1.18378\n",
      "45 \t186   \t0.0426641\t0.126831 \t3.91006e-05\t1.18378\n",
      "46 \t179   \t0.0483238\t0.150214 \t3.91006e-05\t1.18378\n",
      "47 \t186   \t0.0426641\t0.126831 \t3.91006e-05\t1.18378\n",
      "48 \t179   \t0.0352098\t0.094069 \t3.91006e-05\t1.18378\n",
      "49 \t184   \t0.0367963\t0.0976861\t3.91006e-05\t1.18378\n",
      "50 \t182   \t0.0424235\t0.126817 \t3.91006e-05\t1.18378\n",
      "Results for set 2 saved to ./synthesis_100k/NSGA-II_v2\\nsga_ii_results_set_2_0.25_7.0.csv\n",
      "gen\tnevals\tavg    \tstd    \tmin       \tmax    \n",
      "0  \t100   \t3.24323\t3.52667\t0.00694084\t15.6957\n",
      "1  \t183   \t0.730057\t0.655727\t0.00156438\t3.38774\n",
      "2  \t180   \t0.306675\t0.284415\t0.00156438\t1.29965\n",
      "3  \t185   \t0.176467\t0.210092\t0.000134587\t1.09004\n",
      "4  \t180   \t0.12463 \t0.169397\t0.000134587\t1.09004\n",
      "5  \t175   \t0.119503\t0.179202\t0.000134587\t1.09004\n",
      "6  \t182   \t0.10087 \t0.174637\t3.82662e-05\t1.09004\n",
      "7  \t182   \t0.0669331\t0.0872676\t3.82662e-05\t0.258581\n",
      "8  \t189   \t0.0405232\t0.0588587\t3.82662e-05\t0.257317\n",
      "9  \t181   \t0.0282025\t0.0399677\t3.82662e-05\t0.216755\n",
      "10 \t180   \t0.0181879\t0.0200561\t3.82662e-05\t0.0687165\n",
      "11 \t178   \t0.0202298\t0.0243311\t3.82662e-05\t0.0687165\n",
      "12 \t185   \t0.0149423\t0.0165931\t3.82662e-05\t0.0555525\n",
      "13 \t183   \t0.015703 \t0.0183088\t3.82662e-05\t0.0555525\n",
      "14 \t173   \t0.017164 \t0.0210602\t3.82662e-05\t0.0555525\n",
      "15 \t184   \t0.0250032\t0.0266372\t3.82662e-05\t0.0555525\n",
      "16 \t180   \t0.0250042\t0.0266369\t3.82662e-05\t0.0555525\n",
      "17 \t185   \t0.0248064\t0.0265454\t3.82662e-05\t0.0555525\n",
      "18 \t176   \t0.0245281\t0.0264848\t3.82662e-05\t0.0555525\n",
      "19 \t174   \t0.0248211\t0.0265129\t3.82662e-05\t0.0555525\n",
      "20 \t181   \t0.0244199\t0.0263342\t3.82662e-05\t0.0555525\n",
      "21 \t179   \t0.0251984\t0.0267045\t3.82662e-05\t0.0555525\n",
      "22 \t187   \t0.0245906\t0.0264503\t3.82662e-05\t0.0555525\n",
      "23 \t179   \t0.0248959\t0.0266302\t3.82662e-05\t0.0555525\n",
      "24 \t175   \t0.0239865\t0.0261813\t3.82662e-05\t0.0555525\n",
      "25 \t180   \t0.024802 \t0.0265283\t3.82662e-05\t0.0555525\n",
      "26 \t179   \t0.0245497\t0.0264834\t3.82662e-05\t0.0555525\n",
      "27 \t176   \t0.0240901\t0.0261654\t3.82662e-05\t0.0555525\n",
      "28 \t179   \t0.0240033\t0.0260358\t3.82662e-05\t0.0555525\n",
      "29 \t179   \t0.0257518\t0.0269483\t3.82662e-05\t0.0555525\n",
      "30 \t180   \t0.0253891\t0.0267901\t3.82662e-05\t0.0555525\n",
      "31 \t183   \t0.0249665\t0.0266332\t3.82662e-05\t0.0555525\n",
      "32 \t177   \t0.0240544\t0.0261848\t3.82662e-05\t0.0555525\n",
      "33 \t179   \t0.0247613\t0.02655  \t3.82662e-05\t0.0555525\n",
      "34 \t186   \t0.025555 \t0.0268629\t3.82662e-05\t0.0555525\n",
      "35 \t170   \t0.0248195\t0.0265181\t3.82662e-05\t0.0555525\n",
      "36 \t189   \t0.0250153\t0.0265988\t3.82662e-05\t0.0555525\n",
      "37 \t179   \t0.0246693\t0.0264417\t3.82662e-05\t0.0555525\n",
      "38 \t181   \t0.0249975\t0.0266217\t3.82662e-05\t0.0555525\n",
      "39 \t177   \t0.0239912\t0.0261557\t3.82662e-05\t0.0555525\n",
      "40 \t172   \t0.0247126\t0.0265486\t3.82662e-05\t0.0555525\n",
      "41 \t179   \t0.0250164\t0.0265984\t3.82662e-05\t0.0555525\n",
      "42 \t180   \t0.0252121\t0.0266889\t3.82662e-05\t0.0555525\n",
      "43 \t181   \t0.0250032\t0.0266372\t3.82662e-05\t0.0555525\n",
      "44 \t175   \t0.0250189\t0.0266298\t3.82662e-05\t0.0555525\n",
      "45 \t183   \t0.0250092\t0.0266402\t3.82662e-05\t0.0555525\n",
      "46 \t179   \t0.0248445\t0.0265366\t3.82662e-05\t0.0555525\n",
      "47 \t186   \t0.0266279\t0.0274228\t3.82662e-05\t0.0555525\n",
      "48 \t184   \t0.0259792\t0.0272605\t3.82662e-05\t0.0555525\n",
      "49 \t168   \t0.0263238\t0.0274277\t3.82662e-05\t0.0555525\n",
      "50 \t179   \t0.0268538\t0.0274756\t3.82662e-05\t0.0555525\n",
      "Results for set 3 saved to ./synthesis_100k/NSGA-II_v2\\nsga_ii_results_set_3_1.0_2.0.csv\n",
      "gen\tnevals\tavg    \tstd    \tmin       \tmax    \n",
      "0  \t100   \t2.50162\t2.67087\t0.00455546\t14.1276\n",
      "1  \t176   \t0.631892\t0.65614\t0.0039835 \t3.78321\n",
      "2  \t181   \t0.328659\t0.403079\t0.00308514\t3.58448\n",
      "3  \t184   \t0.228541\t0.26886 \t0.00176287\t2.01034\n",
      "4  \t181   \t0.186421\t0.243555\t0.000157356\t1.07841\n",
      "5  \t178   \t0.133407\t0.176462\t0.000157356\t1.07328\n",
      "6  \t173   \t0.111687\t0.137697\t0.000157356\t0.672744\n",
      "7  \t185   \t0.110366\t0.15563 \t0.000157356\t0.672744\n",
      "8  \t182   \t0.127475\t0.185851\t0.000157356\t0.672744\n",
      "9  \t166   \t0.175557\t0.239881\t0.000157356\t0.672744\n",
      "10 \t186   \t0.239566\t0.287423\t0.000157356\t0.672744\n",
      "11 \t182   \t0.318117\t0.333409\t0.000157356\t0.672744\n",
      "12 \t186   \t0.3148  \t0.333165\t0.000157356\t0.672744\n",
      "13 \t184   \t0.321435\t0.33362 \t0.000157356\t0.672744\n",
      "14 \t190   \t0.318549\t0.332087\t0.000157356\t0.672744\n",
      "15 \t185   \t0.322816\t0.333896\t0.000157356\t0.672744\n",
      "16 \t180   \t0.320241\t0.334309\t0.000157356\t0.672744\n",
      "17 \t171   \t0.31695 \t0.334104\t0.000157356\t0.672744\n",
      "18 \t181   \t0.323558\t0.334498\t0.000157356\t0.672744\n",
      "19 \t183   \t0.323558\t0.334498\t0.000157356\t0.672744\n",
      "20 \t181   \t0.322796\t0.333873\t0.000157356\t0.672744\n",
      "21 \t174   \t0.316154\t0.333451\t0.000157356\t0.672744\n",
      "22 \t181   \t0.314024\t0.332529\t0.000157356\t0.672744\n",
      "23 \t178   \t0.310706\t0.332243\t0.000157356\t0.672744\n",
      "24 \t188   \t0.323254\t0.332564\t0.000157356\t0.672744\n",
      "25 \t185   \t0.315231\t0.331846\t0.000157356\t0.672744\n",
      "26 \t180   \t0.316161\t0.333444\t0.000157356\t0.672744\n",
      "27 \t187   \t0.322796\t0.333873\t0.000157356\t0.672744\n",
      "28 \t178   \t0.320639\t0.332934\t0.000157356\t0.672744\n",
      "29 \t180   \t0.324678\t0.333697\t0.000157356\t0.672744\n",
      "30 \t177   \t0.321442\t0.333614\t0.000157356\t0.672744\n",
      "31 \t186   \t0.315994\t0.332493\t0.000157356\t0.672744\n",
      "32 \t176   \t0.311914\t0.331572\t0.000157356\t0.672744\n",
      "33 \t174   \t0.298165\t0.327186\t0.000157356\t0.672744\n",
      "34 \t181   \t0.305663\t0.325328\t0.000157356\t0.672744\n",
      "35 \t187   \t0.323578\t0.334522\t0.000157356\t0.672744\n",
      "36 \t181   \t0.320241\t0.334309\t0.000157356\t0.672744\n",
      "37 \t181   \t0.322802\t0.333866\t0.000157356\t0.672744\n",
      "38 \t183   \t0.322802\t0.333866\t0.000157356\t0.672744\n",
      "39 \t186   \t0.318695\t0.333014\t0.000157356\t0.672744\n",
      "40 \t181   \t0.312505\t0.331216\t0.000157356\t0.672744\n",
      "41 \t180   \t0.313579\t0.333812\t0.000157356\t0.672744\n",
      "42 \t184   \t0.314024\t0.332529\t0.000157356\t0.672744\n",
      "43 \t179   \t0.323996\t0.333167\t0.000157356\t0.672744\n",
      "44 \t180   \t0.32612 \t0.33403 \t0.000157356\t0.672744\n",
      "45 \t177   \t0.319909\t0.332353\t0.000157356\t0.672744\n",
      "46 \t177   \t0.313586\t0.333849\t0.000157356\t0.672744\n",
      "47 \t184   \t0.30482 \t0.332256\t0.000157356\t0.672744\n",
      "48 \t169   \t0.323565\t0.334492\t0.000157356\t0.672744\n",
      "49 \t177   \t0.319478\t0.333675\t0.000157356\t0.672744\n",
      "50 \t182   \t0.317355\t0.332769\t0.000157356\t0.672744\n",
      "Results for set 4 saved to ./synthesis_100k/NSGA-II_v2\\nsga_ii_results_set_4_2.0_1.5.csv\n",
      "gen\tnevals\tavg    \tstd    \tmin      \tmax    \n",
      "0  \t100   \t3.35395\t3.27046\t0.0268164\t15.0102\n",
      "1  \t178   \t0.707081\t0.807829\t0.00171423\t4.57678\n",
      "2  \t190   \t0.343112\t0.52411 \t0.000702858\t4.37241\n",
      "3  \t175   \t0.186733\t0.221512\t0.000702858\t1.16639\n",
      "4  \t183   \t0.152472\t0.184755\t0.000519514\t0.954496\n",
      "5  \t179   \t0.152447\t0.210876\t0.000519514\t0.945461\n",
      "6  \t173   \t0.149417\t0.232436\t0.000218153\t0.945461\n",
      "7  \t181   \t0.147205\t0.24734 \t0.000218153\t0.945461\n",
      "8  \t176   \t0.179018\t0.317316\t0.000159919\t1.13662 \n",
      "9  \t177   \t0.1201  \t0.238029\t0.000159919\t1.13662 \n",
      "10 \t177   \t0.0743212\t0.14921 \t0.000159919\t1.13662 \n",
      "11 \t177   \t0.0549225\t0.0925761\t0.000159919\t1.13662 \n",
      "12 \t184   \t0.0685566\t0.16079  \t0.000159919\t1.13662 \n",
      "13 \t181   \t0.086367 \t0.219824 \t0.000159919\t1.13662 \n",
      "14 \t184   \t0.131295 \t0.309817 \t0.000159919\t1.13662 \n",
      "15 \t184   \t0.229314 \t0.433595 \t0.000159919\t1.13662 \n",
      "16 \t170   \t0.45657  \t0.5501   \t0.000159919\t1.13662 \n",
      "17 \t181   \t0.4624   \t0.551138 \t0.000159919\t1.13662 \n",
      "18 \t187   \t0.504408 \t0.560717 \t0.000159919\t1.13662 \n",
      "19 \t185   \t0.432582 \t0.534933 \t0.000105858\t1.13662 \n",
      "20 \t175   \t0.29266  \t0.46452  \t0.000105858\t1.13662 \n",
      "21 \t176   \t0.0528744\t0.0780297\t0.000105858\t0.637177\n",
      "22 \t178   \t0.0483533\t0.0768394\t0.000105858\t0.637177\n",
      "23 \t184   \t0.0469623\t0.0953648\t0.000105858\t0.637177\n",
      "24 \t183   \t0.0549953\t0.125405 \t0.000105858\t0.637177\n",
      "25 \t176   \t0.0749303\t0.160532 \t0.000105858\t0.637177\n",
      "26 \t187   \t0.113438 \t0.200698 \t0.000105858\t0.637177\n",
      "27 \t184   \t0.0827243\t0.129848 \t0.000105858\t0.637177\n",
      "28 \t174   \t0.0684815\t0.0869473\t0.000105858\t0.637177\n",
      "29 \t177   \t0.0685865\t0.0868999\t0.000105858\t0.637177\n",
      "30 \t177   \t0.0734759\t0.103572 \t0.000105858\t0.637177\n",
      "31 \t180   \t0.066382 \t0.0773539\t0.000105858\t0.637177\n",
      "32 \t168   \t0.0677914\t0.0867768\t0.000105858\t0.637177\n",
      "33 \t177   \t0.0672877\t0.086679 \t0.000105858\t0.637177\n",
      "34 \t180   \t0.0637301\t0.0765993\t0.000105858\t0.637177\n",
      "35 \t177   \t0.064846 \t0.0860879\t0.000105858\t0.637177\n",
      "36 \t179   \t0.0631678\t0.0856198\t0.000105858\t0.637177\n",
      "37 \t186   \t0.0632337\t0.0766299\t0.000105858\t0.637177\n",
      "38 \t185   \t0.0651033\t0.086189 \t0.000105858\t0.637177\n",
      "39 \t184   \t0.0680828\t0.0868069\t0.000105858\t0.637177\n",
      "40 \t185   \t0.0679511\t0.0867234\t0.000105858\t0.637177\n",
      "41 \t180   \t0.0677604\t0.086666 \t0.000105858\t0.637177\n",
      "42 \t183   \t0.0681979\t0.0866457\t0.000105858\t0.637177\n",
      "43 \t185   \t0.0677532\t0.0865237\t0.000105858\t0.637177\n",
      "44 \t179   \t0.0681915\t0.0866511\t0.000105858\t0.637177\n",
      "45 \t171   \t0.0680098\t0.0868377\t0.000105858\t0.637177\n",
      "46 \t180   \t0.0663719\t0.0864396\t0.000105858\t0.637177\n",
      "47 \t187   \t0.0676699\t0.0866562\t0.000105858\t0.637177\n",
      "48 \t180   \t0.0662244\t0.0863205\t0.000105858\t0.637177\n",
      "49 \t175   \t0.0632537\t0.0856042\t0.000105858\t0.637177\n",
      "50 \t178   \t0.0638807\t0.0940971\t0.000105858\t0.637177\n",
      "Results for set 5 saved to ./synthesis_100k/NSGA-II_v2\\nsga_ii_results_set_5_2.5_1.0.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to run NSGA-II for a given set of target conditions\n",
    "def run_nsga_ii(target_d_max, target_gr_min, filename):\n",
    "    # Set the target values in the evaluate function\n",
    "    def evaluate(individual):\n",
    "        # d_max_pred, gr_min_pred = surrogate_model_predict(individual)\n",
    "        # d_max_pred, gr_min_pred = validate(individual) # with ground truth\n",
    "        d_max_pred, gr_min_pred = surrogate_model_predict(individual) # with surrogate model\n",
    "        return abs(d_max_pred - target_d_max), abs(gr_min_pred - target_gr_min)\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "    # Run the NSGA-II algorithm\n",
    "    pop, stats, hof = main()\n",
    "\n",
    "    # Convert the hall of fame individuals to a DataFrame\n",
    "    pop_df = pd.DataFrame([ind for ind in pop], columns=['l2', 'l3', 'l4', 'EE_x', 'EE_y'])\n",
    "\n",
    "    # Save to CSV\n",
    "    pop_df.to_csv(filename, index=False)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"./synthesis_100k/NSGA-II_v2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Target conditions sets\n",
    "target_conditions = [\n",
    "    (0.4, 5.0),\n",
    "    (1.0, 2.0),\n",
    "    (2.0, 1.5),\n",
    "    (2.5, 1.0)\n",
    "]\n",
    "\n",
    "# target_conditions = [\n",
    "#     (2.5, 10.0)\n",
    "# ]\n",
    "\n",
    "# Run NSGA-II for each set of target conditions and save results\n",
    "for i, (target_d_max, target_gr_min) in enumerate(target_conditions, start=1):\n",
    "    filename = os.path.join(output_dir, f\"nsga_ii_results_set_{i}_{target_d_max}_{target_gr_min}.csv\")\n",
    "    run_nsga_ii(target_d_max, target_gr_min, filename)\n",
    "    print(f\"Results for set {i} saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.150852</td>\n",
       "      <td>4.420709</td>\n",
       "      <td>2.314502</td>\n",
       "      <td>-1.631098</td>\n",
       "      <td>-3.555529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032455</td>\n",
       "      <td>0.355032</td>\n",
       "      <td>0.110967</td>\n",
       "      <td>0.396963</td>\n",
       "      <td>0.404783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.051599</td>\n",
       "      <td>1.340248</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>-1.714867</td>\n",
       "      <td>-3.613034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.147655</td>\n",
       "      <td>4.470260</td>\n",
       "      <td>2.325664</td>\n",
       "      <td>-1.683739</td>\n",
       "      <td>-3.613034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.147655</td>\n",
       "      <td>4.470260</td>\n",
       "      <td>2.325664</td>\n",
       "      <td>-1.683739</td>\n",
       "      <td>-3.613034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.147655</td>\n",
       "      <td>4.470260</td>\n",
       "      <td>2.325664</td>\n",
       "      <td>-1.683739</td>\n",
       "      <td>-3.613034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.457356</td>\n",
       "      <td>4.470260</td>\n",
       "      <td>2.404933</td>\n",
       "      <td>1.976494</td>\n",
       "      <td>0.316255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000\n",
       "mean      0.150852     4.420709     2.314502    -1.631098    -3.555529\n",
       "std       0.032455     0.355032     0.110967     0.396963     0.404783\n",
       "min       0.051599     1.340248     0.999701    -1.714867    -3.613034\n",
       "25%       0.147655     4.470260     2.325664    -1.683739    -3.613034\n",
       "50%       0.147655     4.470260     2.325664    -1.683739    -3.613034\n",
       "75%       0.147655     4.470260     2.325664    -1.683739    -3.613034\n",
       "max       0.457356     4.470260     2.404933     1.976494     0.316255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pop).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "0.9999826 1.9533465\n",
      "0.9999826 1.9533465\n",
      "0.99892783 1.9909515\n",
      "1.2482585 2.0004976\n",
      "1.2482585 2.0004976\n",
      "0.96006835 2.001602\n",
      "1.1336087 2.0015666\n",
      "1.1876624 2.001529\n",
      "1.2482585 2.0004976\n",
      "1.1876624 2.001529\n",
      "1.1336087 2.0015666\n",
      "1.0187949 1.9979122\n",
      "0.9893091 1.9965439\n",
      "0.99892783 1.9909515\n",
      "0.9975649 2.0069537\n",
      "0.9975649 2.0069537\n",
      "0.96006835 2.001602\n",
      "1.0028714 1.9937124\n",
      "1.0028714 1.9937124\n",
      "1.0097741 1.9947855\n",
      "1.0097741 1.9947855\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n",
      "1.5530347 1.9995642\n"
     ]
    }
   ],
   "source": [
    "from src.validate import validate\n",
    "\n",
    "for i in pop:\n",
    "    d_max_pred, gr_min_pred = surrogate_model_predict(i)\n",
    "    print(d_max_pred, gr_min_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
